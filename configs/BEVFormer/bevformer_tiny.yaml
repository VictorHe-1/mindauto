system:
  mode: 0 # 0 for graph mode, 1 for pynative mode in MindSpore
  distribute: False
  amp_level: 'O0'
  seed: 0 # BEVFormer seed is 0
  val_while_train: False
  drop_overflow_update: False
  ckpt_save_policy: top_k
  ckpt_max_keep: 6
  device_id: 6
  log_interval: 1

dim: &dim 256
pos_dim: &pos_dim 128
ffn_dim: &ffn_dim 512
num_levels: &num_levels 1
bev_h: &bev_h 50
bev_w: &bev_w 50
point_cloud_range: &point_cloud_range [-51.2, -51.2, -5.0, 51.2, 51.2, 3.0]
voxel_size: &voxel_size [0.2, 0.2, 8]
img_norm_cfg: &img_norm_cfg
  mean: [123.675, 116.28, 103.53]
  std: [58.395, 57.12, 57.375]
  to_rgb: True

class_names: &class_names ['car', 'truck', 'construction_vehicle', 'bus', 'trailer', 'barrier', 'motorcycle', 'bicycle', 'pedestrian', 'traffic_cone']

input_modality: &input_modality
  use_lidar: False
  use_camera: True
  use_radar: False
  use_map: False
  use_external: True

encoder_attn_cfg: &encoder_attn_cfg
  - type: 'TemporalSelfAttention'
    embed_dims: *dim
    num_levels: 1
  - type: 'SpatialCrossAttention'
    pc_range: *point_cloud_range
    deformable_attention:
      type: 'MSDeformableAttention3D'
      embed_dims: *dim
      num_points: 8
      num_levels: *num_levels
    embed_dims: *dim

decoder_attn_cfg: &decoder_attn_cfg
  - type: 'MultiheadAttention'
    embed_dims: *dim
    num_heads: 8
    dropout: 0.1
  - type: 'CustomMSDeformableAttention'
    embed_dims: *dim
    num_levels: 1

model:
  type: 'BEVFormer'
  use_grid_mask: True
  video_test_mode: True
  img_backbone:
    type: ResNet
    depth: 50
    num_stages: 4
    out_indices: (3, )
    frozen_stages: 1
    norm_cfg:
      type: BN
      requires_grad: False
    norm_eval: True
    style: pytorch
    training_mode: True # set it to True when training
    ckpt_load_path: ckpts/resnet50_ms.ckpt
  img_neck:
    type: FPN
    in_channels: [2048]
    out_channels: *dim
    start_level: 0
    add_extra_convs: 'on_output'
    num_outs: *num_levels
    relu_before_extra_convs: True
  pts_bbox_head:
    type: BEVFormerHead
    bev_h: *bev_h
    bev_w: *bev_w
    num_query: 900
    num_classes: 10
    in_channels: *dim
    sync_cls_avg_factor: True
    with_box_refine: True
    as_two_stage: False
    transformer:
      type: PerceptionTransformer
      rotate_prev_bev: True
      use_shift: True
      use_can_bus: True
      embed_dims: *dim
      encoder:
        type: BEVFormerEncoder
        num_layers: 3
        pc_range: *point_cloud_range
        num_points_in_pillar: 4
        return_intermediate: False
        transformerlayers:
          type: BEVFormerLayer
          attn_cfgs: *encoder_attn_cfg
          feedforward_channels: *ffn_dim
          ffn_dropout: 0.1
          operation_order: ['self_attn', 'norm', 'cross_attn', 'norm', 'ffn', 'norm']
      decoder:
        type: DetectionTransformerDecoder
        num_layers: 6
        return_intermediate: True
        transformerlayers:
          type: DetrTransformerDecoderLayer
          attn_cfgs: *decoder_attn_cfg
          feedforward_channels: *ffn_dim
          ffn_dropout: 0.1
          operation_order: ['self_attn', 'norm', 'cross_attn', 'norm', 'ffn', 'norm']
    loss_cls:
      type: 'FocalLoss'
      use_sigmoid: True
      gamma: 2.0
      alpha: 0.25
      loss_weight: 2.0
    loss_bbox:
      type: 'L1Loss'
      loss_weight: 0.25
    loss_iou:
      type: 'GIoULoss'
      loss_weight: 0.0
    bbox_coder:
      type: 'NMSFreeCoder'
      post_center_range: [-61.2, -61.2, -10.0, 61.2, 61.2, 10.0]
      pc_range: *point_cloud_range
      max_num: 300
      voxel_size: *voxel_size
      num_classes: 10
    positional_encoding:
      type: 'LearnedPositionalEncoding'
      num_feats: *pos_dim
      row_num_embed: 50
      col_num_embed: 50
  train_cfg:
    pts:
      grid_size: [512, 512, 1]
      voxel_size: *voxel_size
      point_cloud_range: *point_cloud_range
      out_size_factor: 4
      assigner:
        type: HungarianAssigner3D
        cls_cost:
          type: FocalLossCost
          weight: 2.0
        reg_cost:
          type: BBox3DL1Cost
          weight: 0.25
        iou_cost:
          type: IoUCost
          weight: 0.0
        pc_range: *point_cloud_range

scheduler:
  scheduler: CosineAnnealing
  lr: 2e-4
  warmup: linear
  warmup_iters: 500
  warmup_ratio: 1.0/3
  min_lr_ratio: 1e-3
  num_epochs: 24

optimizer:
  opt: AdamW
  filter_bias_and_bn: False
  weight_decay: 0.01

# only used for mixed precision training
loss_scaler:
  type: dynamic
  loss_scale: 512
  scale_factor: 2
  scale_window: 1000

train: #  ema: True
  ckpt_save_dir: './tmp_det'
  dataset_sink_mode: False
  dataset:
    type: &dataset_type CustomNuScenesDataset
    data_root: ./data
    ann_file: nuscenes/nuscenes_infos_temporal_train.pkl
    pipeline:
      - LoadMultiViewImageFromFiles:
          to_float32: True
      - PhotoMetricDistortionMultiViewImage:
      - LoadAnnotations3D:
          with_bbox_3d: True
          with_label_3d: True
          with_attr_label: False
      - ObjectRangeFilter:
          point_cloud_range: *point_cloud_range
      - ObjectNameFilter:
          classes: *class_names
      - PadLabel:
          padding_size: 350
          padding_value: 0  # padding value must be in range [0, 9]
      - NormalizeMultiviewImage: *img_norm_cfg
      - RandomScaleImageMultiViewImage:
          scales: [0.5]
      - PadMultiViewImage:
          size_divisor: 32
      - DefaultFormatBundle3D:
          class_names: *class_names
      - CustomCollect3D:
          keys: ['gt_bboxes_3d', 'gt_labels_3d', 'img', 'gt_labels_mask']
    use_grid_mask: True
    classes: *class_names
    modality: *input_modality
    test_mode: False
    use_valid_flag: True
    bev_size: &bev_size [50, 50]
    queue_length: &queue_length 3
    box_type_3d: LiDAR
    bs: 1
    pc_range: *point_cloud_range
    num_points_in_pillar: 4
    output_columns: [ 'img_metas', 'gt_bboxes_3d', 'gt_labels_3d', 'img', 'gt_labels_mask', 'grid_mask_img', 'max_len', 'indexes', 'reference_points_cam', 'bev_mask', 'shift']

  loader:
    shuffle: False
    batch_size: 1 # only support batch_size = 1
    drop_remainder: True
    num_workers: 1

eval:
  ckpt_load_path: 'ckpts/bevformer_tiny.ckpt'
  dataset_sink_mode: False
  dataset:
    type: *dataset_type
    data_root: ./data
    ann_file: nuscenes/nuscenes_infos_temporal_val.pkl
    pipeline:
      - LoadMultiViewImageFromFiles:
          to_float32: True
      - NormalizeMultiviewImage: *img_norm_cfg
      - MultiScaleFlipAug3D:
          img_scale: (1600, 900)
          pts_scale_ratio: 1
          flip: False
          transforms:
            - RandomScaleImageMultiViewImage:
                scales: [ 0.5 ]
            - PadMultiViewImage:
                size_divisor: 32
            - DefaultFormatBundle3D:
                class_names: *class_names
                with_label: False
            - CustomCollect3D:
                keys: [ 'img' ]
    use_grid_mask: True
    bs: 1
    pc_range: *point_cloud_range
    num_points_in_pillar: 4
    test_mode: True
    output_columns: [ 'img_metas', 'img' ]
    bev_size: *bev_size
    classes: *class_names
    modality: *input_modality

  loader:
    shuffle: False
    batch_size: 1
    drop_remainder: False
    num_workers: 1
